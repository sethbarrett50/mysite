<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />

    <meta name="robots" content="index, follow">

    <meta name="description"
        content="Welcome to my personal website! Here, you will find information about my professional experience, education, and a short blog where I share my thoughts and insights on a variety of topics. As a professional in the field of computer science, I am excited to share my accomplishments and experiences with you, and I hope that my website serves as a helpful resource for anyone interested in computer science. Thank you for visiting!">
    <meta name="keywords"
        content="Seth, Seth Barrett, Augusta, Augusta University, AU, SCCS, School of Computer and Cyber Science, Barrett, Dorai, PhD, Computer science, Cybersecurity, Digital forensics, Machine learning, Bioinformatics, Internet of things, Networking, Vulnerability analysis, Research, Education, PhD degree, Cyber sciences, Data science, Cybersecurity research, Digital forensics research, Machine learning research, Bioinformatics research, Internet of things research, Networking research, Vulnerability analysis research, Computer science research, Cybersecurity education, Digital forensics education, Machine learning education, Bioinformatics education, Internet of things education, Networking education, Vulnerability analysis education, Computer science education, PhD program, Cybersecurity program, Digital forensics program, Machine learning program, Bioinformatics program, Internet of things program, Networking program, Vulnerability analysis program, Computer science program, Graduate studies, Cybersecurity graduate studies, Digital forensics graduate studies, Machine learning graduate studies, Bioinformatics graduate studies, Internet of things graduate studies, Networking graduate studies, Vulnerability analysis graduate studies, Computer science graduate studies, PhD studies, Cybersecurity studies, Digital forensics studies, Machine learning studies, Bioinformatics studies, Internet of things studies, Networking studies, Vulnerability analysis studies, Computer science studies, Academic research, Cybersecurity research, Digital forensics research, Machine learning research, Bioinformatics research, Internet of things research, Networking research, Vulnerability analysis research, Computer science research, Professional development, Cybersecurity professional development, Digital forensics professional development, Machine learning professional development, Bioinformatics professional development, Internet of things professional development, Networking professional development, Vulnerability analysis professional development, Computer science professional development, Continuing education, Cybersecurity continuing education, Digital forensics continuing education, Machine learning continuing education, Bioinformatics continuing education, Internet of things continuing education, Networking continuing education, Vulnerability analysis continuing education, Computer science continuing education, Career advancement, Cybersecurity career advancement, Digital forensics career advancement, Machine learning career advancement, Bioinformatics career advancement, Internet of things career advancement, Networking career advancement, Vulnerability analysis career advancement, Computer science career advancement, Professional portfolio, Cybersecurity portfolio, Digital forensics portfolio, Machine learning portfolio, Bioinformatics portfolio, Internet of things portfolio, Networking portfolio">
    <meta name="author" content="Seth Barrett">


    <meta property="og:site_name" content="Seth Barrett - Home">
    <meta name="twitter:domain" property="twitter:domain" content="sethbarrett.xyz">
    <meta name="og:title" property="og:title" content="Seth Barrett - Home">
    <meta property="og:description"
        content="Welcome to my personal website! Here, you will find information about my professional experience, education, and a short blog where I share my thoughts and insights on a variety of topics. As a professional in the field of computer science, I am excited to share my accomplishments and experiences with you, and I hope that my website serves as a helpful resource for anyone interested in computer science. Thank you for visiting!">
    <meta name="twitter:description" property="twitter:description"
        content="Welcome to my personal website! Here, you will find information about my professional experience, education, and a short blog where I share my thoughts and insights on a variety of topics. As a professional in the field of computer science, I am excited to share my accomplishments and experiences with you, and I hope that my website serves as a helpful resource for anyone interested in computer science. Thank you for visiting!">
    <meta name="og:image" content="https://sethbarrett.xyz/photos/me.jpg">


    <meta property="twitter:card" content="https://sethbarrett.xyz/photos/me.jpg">
    <meta name="twitter:image:src" property="twitter:image:src" content="https://sethbarrett.xyz/photos/me.jpg">
    <meta name="twitter:image" property="twitter:image" content="https://sethbarrett.xyz/photos/me.jpg">
    <meta name="og:image:alt" property="og:image:alt" content="Me">

    <meta property="og:url" content="sethbarrett.xyz">
    <meta property="og:type" content="website">
    <title>Seth Barrett - Home</title>


    <!-- Update CSS Versions when changed -->
    <link rel="stylesheet" href="selfie.css?v=1.0.1" />
    <link rel="stylesheet" href="selfie_tablet.css?v=1.0.1" media="only screen and (max-width: 1000px)" />
    <link rel="stylesheet" href="selfie_mobile.css?v=1.0.1" media="only screen and (max-width: 600px)" />
</head>

<body>
    <div id="wrapper">
        <header>
            <h1>Seth Barrett</h1>
            <h2>Home</h2>
        </header>
        <nav>
            <ul>
                <li><a href="index.html">Home</a></li>
                <li><a href="experience.html">Experience</a></li>
                <li><a href="education.html">Education</a></li>
                <li><a href="blog.html">Blog</a></li>
                <li><a href="contact.html">Contact Me</a></li>
            </ul>
        </nav>
        <main>
            <div id="blog">
                <h3>The Daily Grind</h3>
                <!-- 
                        Have blocks of blogs
                        Have title, date for each entry
                        Below will be the main content for the posts
                -->

                <!-- <div class="blog">
                    <h4>Jan 1st, 2022</h4>
                    <div class='title'>Planned Website Features</div>

                    <p>
                        -Individual Pages for blog Posts
                        -Blog is first place, swap with current index
                        -Better image sourcing + size convert
                        -Sources for each blog entry, particularly for photos

                        -I will remember this later
                    </p>
                </div> -->

                <!-- <div class="blog">
                    <h4>December 31st, 2022</h4>
                    <div class='title'>hardening</div>
                    
                    <p>
                        security
                        
                        As mentioned above, SSH keys
                        Different users than root
                            -Add them to sudo group
                        Changed the /etc/ssh/sshd_config file to only allow login w/ ssh keys
                        Went to /etc/nginx/nginx.conf, uncomented server_tokens off and reloaded nginx to not show nginx version numbers on error pages
                        Vultr comes preinstalled with ufw
                        
                    </p>
                </div> -->



                <!-- <div class="blog">
                    <h4>December 30th, 2022</h4>
                    <div class='title'>Streamlining Website Maintenance with Shell Scripts and Cronjobs</div>
                    <p>
                        As we saw in yesterday's post, it's important to keep your website up to date in order to maintain security and ensure that everything is running smoothly. 
                        One way to automate this process is by using a shell script. 
                        In this post, we'll go over how to set up a script that will automatically update your website whenever you make changes.
                    </p>
                    <p>
                        First, you'll need to set up SSH keys for your server. 
                        This will allow you to securely connect to the server and run commands remotely.
                        To do this, you can use the `ssh-keygen` command to generate a new SSH key, and then use `ssh-copy-id` to connect the key to your site's SSH.
                    </p>
                    <p>
                        Once you have your SSH keys set up, you can create a shell script that takes an argument representing your commit message. 
                        This script will commit and push any updates to your website's repository, log in to the remote server using the expect command and your new SSH key, change to your website repository location, and pull the update. 
                        Finally, the script will exit the server.
                    </p>
                    <p>
                        Here's the shell script in action:
                    </p>
                    <p>
                        <pre>
                            #!/bin/bash
                            
                            # Run git commit with the -a and -m flags
                            #Uses the command line argument as the commit message
                            git commit -a -m "$1"
                            
                            # Push the committed changes to the remote repository
                            git push
                            
                            # Use expect to automate the login process
                            expect <<- DONE
                              # Wait for the login prompt and send the login command
                              spawn ssh root@sethbarrett.xyz
                            
                              # Wait for the command prompt and send the cd command
                              expect "$"
                              send "cd /var/www/mysite/\r"
                            
                              # Wait for the command prompt and send the git pull command
                              expect "$"
                              send "git pull\r"
                            
                              # Exit remote server
                              expect "$"
                              send "exit"
                              
                              # Exit the expect script
                              expect eof
                            DONE
                        </pre>                            
                    </p>
                    <p>
                        With this script in place, you can easily update your website whenever you make changes, without having to log in to the server manually. 
                        This can save you a lot of time and effort, and ensures that your website is always up to date.
                    </p>
                    <p>
                        Cronjobs are a powerful tool for automating tasks on a Linux server. 
                        By using cron, you can schedule a script or command to run at specific intervals, such as every hour, day, week, or month. 
                        This can be especially useful for tasks that need to be run on a regular basis, such as website updates or backups.
                        Yesterday, I used it to set up a cronjob to automatically renew my websites certificate monthly so I don't have to check all the time.
                    </p>
                    <p>
                        In the future, I plan on utilizing cronjobs to further automate the maintenance and management of my website. 
                        For example, I could set up a cronjob to run the shell script we discussed above every day at a certain time, to ensure that my website is always up to date. 
                        I could also set up cronjobs for other tasks, such as cleaning up old log files or sending notifications when certain events occur. 
                        By using cronjobs, I can save time and effort by automating these tasks, and ensure that my website is always running smoothly.
                    </p>
                    Desc: In this blog post, we will discuss how to automate the process of updating your website using a shell script. We will go over the steps for setting up SSH keys for your server and creating a shell script that can commit and push updates to your website's repository, log in to the server, and pull the updates. We will also provide an example of the shell script in action. Finally, we will introduce the concept of cronjobs and how they can be used to further automate the maintenance and management of your website.
                </div> -->
                

                <div class="blog">
                    <h4>December 29th, 2022</h4>
                    <div class='title'>Step-by-Step Guide to Setting Up Your Own Website: From Domain Name to Secure Server</div>
                    <img src="photos/epik.jpeg" alt="epik" width="250" height="250" />

                    <p>
                        Setting up a website can seem like a daunting task, especially if you're new to the process. 
                        However, with the right tools and knowledge, it can be a relatively straightforward process.
                    </p>
                    <p>
                        In this blog post, we'll cover the steps I took to set up my website, including renting a domain name, choosing a server hosting provider, and configuring the server with Nginx.
                    </p>
                    <p>
                        First, I used a company called epik to rent my domain name. 
                        The process was fairly quick, taking about a quarter of a day before my domain name was registered to me.
                        Its also pretty cool that epik supports cryptocurrency as a payment method.
                    </p>
                    <p>
                        Next, I chose Vultr as my server hosting provider, opting for a cloud compute Debian general purpose server. 
                        I chose the cheapest size that still allowed for IPv4, which cost around $5 per month.
                        <a href="https://www.vultr.com/?ref=9325408">If you'd like to get $100 credit on Vultr for any of your server needs, use my referall link here when you sign up!</a>
                    </p>
                    <img src="photos/vultr.jpeg" alt="Vultr" width="250" height="445" />
                    <p>
                        Once I had my server set up, I linked the server's IPv4 and IPv6 addresses with the DNS records on Epik. 
                        This ensured that my website could be accessed using the domain name I had rented.
                    </p>
                    <p>
                        I decided to use Nginx as my web server, rather than the more traditional Apache. 
                        While I was familiar with Apache, I wanted to try something new and found Nginx to be fairly easy to use.
                    </p>
                    <p>
                        After setting up the website and placing my HTML files in the /var/www/mysite directory, I used Certbot to generate a certificate for my site. 
                        This ensures that all communication between my website and its users is encrypted and secure.
                    </p>
                    <p>
                        Finally, I set up a cronjob to automate the process of renewing my certificates, ensuring that my website remains secure over time.
                    </p>
                    <p>
                        Overall, the process of setting up a website may seem intimidating at first, but with the right tools and knowledge, it can be a relatively straightforward process. 
                        Whether you're a seasoned pro or a beginner, following these steps can help you get your website up and running in no time.
                    </p>
                    <!-- Desc: In this blog post, learn the steps for setting up a website, including renting a domain name, choosing a server hosting provider, and configuring the server with Nginx. We also cover the use of Certbot for secure communication and setting up a cronjob for certificate renewal. Whether you're a beginner or a pro, these steps can help you get your website up and running smoothly. -->
                </div>

                <div class="blog">
                    <h4>December 28th, 2022</h4>
                    <div class='title'>Using C# and Regular Expressions for Data Analysis in My Vault Research Project</div>
                    <img src="photos/regEx.jpeg" alt="C# Regular Expression Language" width="250" height="445" />
                    <p>
                        I've recently been using C#'s regular expression language for my Vault research project, specifically for finding Android permissions data and Java encryption and security package imports within the java files of decompiled apks from the aptoide store.
                    </p>
                    <p>
                        One of the main benefits of using regular expressions is the ability to easily search through large amounts of data and pull out specific patterns or groups of characters. 
                        In this case, I'm using the regex function to search through all the files within each directory related to each decompiled application and find instances of "java.security." or "javax.crypto.".
                    </p>
                    <p>
                        To do this, I'm using the following piece of C# code:
                        <span style="font-family: monospace; color: #333;"><code>Regex packEx = new Regex(@"(java.security.\w*|javax.crypto.\w*)");</code></span>
                        The use of grouping in this regular expression is essential for finding these specific patterns within the data.
                        By using the parentheses, we are able to group together the "java.security." and "javax.crypto." patterns, and the use of the pipe symbol (|) allows us to search for either of these patterns. 
                        The \w* characters at the end of each group allow for any combination of alphanumeric characters to follow these patterns.
                    </p>
                    <p>
                        In addition to searching for Java packages, I have also been using regular expressions to find instances of Android permission usage in the files. 
                        To do this, I am using the following regular expression: <span style="font-family: monospace; color: #333;"><code>@"([\w])([^(]{[^{](android.permission.[A-Z_])"</code></span>
                    </p>
                    <p>
                        This regular expression searches for any instance of "android.permission." followed by one or more capitalized and underscore-separated characters. 
                        The use of the square brackets, parentheses, and curly braces allows for the search to be specific to the use of Android permissions within the code and to capture the method and class names that the permission usage is found in.
                    </p>
                    <p>
                        Compiling the regular expression before using it in loops is also an important consideration for efficiency. 
                        When a regular expression is compiled, it is converted into an optimized form that is faster to execute. 
                        This is especially important when running the regex function on a large number of files within a loop.
                    </p>
                    <p>
                        As an undergraduate, I had the opportunity to learn C# with Dr. Dowell, and I have continued to enjoy using this language in my research and professional endeavors. 
                        In my recent work on the Vault project, I found C#'s regular expression language and the ability to walk through file trees recursively to be particularly useful tools.
                    </p>
                    <p>
                        While using C# on a Mac has presented some challenges, such as the lack of a fully-featured visual studio edition, I have found that the benefits of using this language far outweigh any difficulties. 
                        I am grateful for the opportunity to have learned C# during my undergraduate studies, and I continue to enjoy using it in my work.
                    </p>
                    <!-- Desc: Learn how to use C# regular expression language for searching and finding specific patterns within data, including Android permission usage and Java encryption and security package imports. This blog post also covers the importance of compiling regular expressions for efficiency and the benefits of using C# in research and professional endeavors. -->
                </div>
                    
                
                <div class="blog">
                    <h4>December 27th, 2022</h4>
                    <div class='title'>Progress Report on PhD Research Project: Detecting Vault Apps using Machine Learning</div>
                    <img src="photos/aptoide.png" alt="Aptoide Logo" width="250" height="445" />
                    <p>
                        Hi everyone,
                    </p>
                    <p>
                        I wanted to give an update on the progress of my PhD research project, which focuses on using
                        machine learning to detect vault apps in the Aptoide 3rd party Android app store.
                        As some of you may know, I've been working on this project since last March and it will be a
                        part of my dissertation.
                    </p>
                    <p>
                        So far, we have scraped 500 apps from the app store and collected all the text and images from
                        the individual sites.
                        We have also downloaded any freely available apk files associated with the apps and decompiled
                        them into java files.
                        Using regular expressions, we are searching for any permissions data or imported packages in the
                        files that may suggest that a particular app is a vault app.
                    </p>
                    <p>
                        The data we gather through this process will be used to train a machine learning program to
                        detect these types of apps.
                        The vault apps will serve as positive examples, while the non-vault apps will be negative
                        examples.
                    </p>
                    <p>
                        Our goal is to use this research to create a piece of software that can help law enforcement
                        locate hidden vault apps on the devices of bad actors, such as foreign agents or drug dealers,
                        and determine how the information is stored (e.g. locally on the device, in an accessible cloud
                        storage service, or securely encrypted locally on the device).
                    </p>
                    <p>
                        Overall, the project is progressing well and I'm excited to see the results of our machine
                        learning program once it is trained on the data we've collected.
                        I'll be sure to keep you updated on any further developments.
                    </p>
                    <p>
                        Thanks for reading!
                    </p>
                    <!-- Desc: Get an update on my PhD research project using machine learning to detect vault apps in the Aptoide 3rd party Android app store. The project involves scraping and collecting data from app sites, downloading and decompiling apk files, and using regular expressions to search for permissions data and imported packages. The goal is to create software to help law enforcement locate and determine how information is stored in hidden vault apps. The project is progressing well and I am excited to see the results of the machine learning program once it is trained on collected data. -->
                </div>

                <div class="blog">
                    <h4>December 26th, 2022</h4>
                    <div class='title'>Learning and Growing as a PhD Researcher in Digital Forensics and Computer
                        Science</div>
                    <img src="photos/wanderer.jpeg" alt="Wanderer" width="250" height="445" />
                    <p>
                        It's hard to believe that it's already been seven months since I started my my research at
                        Augusta University in digital forensics, machine learning, and cyber security.
                        Time has flown by as I've immersed myself in my research, learning about new technologies and
                        techniques that I never would have even known existed before.
                    </p>
                    <p>
                        As I look back on these past seven months, I'm amazed at how much I've learned and how much my
                        research has grown.
                        I've had the opportunity to work with some truly brilliant minds in the field, and have had the
                        chance to contribute my own ideas and insights to our work.
                    </p>
                    <p>
                        One of the most rewarding aspects of this experience has been seeing the tangible results of my
                        research.
                        Whether it's through the development of a new tool or the identification of a previously unknown
                        vulnerability, it's incredibly satisfying to see my work make a real impact.
                    </p>
                    <p>
                        While the road through academia can be challenging at times, it's also been an incredible
                        journey filled with growth and discovery.
                        I'm excited to see where the next few years will take me, and I can't wait to see what new
                        discoveries and insights I'll uncover along the way.
                    </p>
                    <p>
                        As I embark on the next phase of my education and career, I am excited to take on a number of
                        new challenges and projects.
                        Currently, I am working on three research projects that are at the forefront of my focus.
                        In addition, I am beginning my PhD classes, which I am eager to dive into and learn as much as
                        possible.
                    </p>
                    <p>
                        I am also taking on the task of learning about setting up and hosting a website and mail server.
                        This is a new area for me, and I am excited to add this skill to my toolkit.
                    </p>
                    <p>
                        Finally, I am committed to continuing my learning journey and expanding my knowledge of
                        programming languages, particularly those that are applicable to new use cases and paradigms
                        that I have not yet encountered.
                        I believe that staying up-to-date on the latest technologies and approaches is essential for
                        success in this field, and I am eager to take on this challenge.
                    </p>
                    <p>
                        Overall, I am excited to see what the future holds and to continue pushing myself to be the best
                        that I can be.
                    </p>
                    <!-- Desc: Reflect on seven months of research in digital forensics, machine learning, and cyber security at Augusta University. I have had the opportunity to work with brilliant minds, contribute their own ideas, and see tangible results from their work. I am currently working on three research projects, starting their PhD classes, learning about website and mail server setup, and expanding their knowledge of programming languages. I am excited for the future and committed to continuing their learning journey and staying up-to-date on the latest technologies and approaches. -->
                </div>

            </div>
        </main>
        <footer>
            Copyright &copy; [2022], [Seth Barrett]
            <br />
            <b>
                Email:
            </b>
            <a href="mailto:sebarrett@augusta.edu">sebarrett@augusta.edu</a>
            <br />
            <b>
                Profile:
            </b>
            <a href="https://www.linkedin.com/in/975833b14567812q">LinkedIn</a>
            <br />
            <b>
                GitHub:
            </b>
            <a href="https://github.com/sethbarrett50">GitHub</a>
        </footer>
    </div>
</body>

</html>