<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />

    <meta name="robots" content="index, follow">

    <meta name="description"
        content="In this post, we'll learn about using the requests and Beautiful Soup libraries in Python for web scraping and parsing. We'll look at how to make HTTP requests with requests, and how to extract and navigate data from HTML and XML documents with Beautiful Soup. We'll also see how to use these libraries together to scrape data from a webpage. Requests and Beautiful Soup are popular and well-documented libraries that are useful for a variety of tasks such as data mining, data analytics, and automating tasks.">
    <meta name="keywords"
        content="Seth, Seth Barrett, Augusta, Augusta University, AU, SCCS, School of Computer and Cyber Science, Barrett, Dorai, PhD, Computer science, Cybersecurity, Digital forensics, Machine learning, Bioinformatics, Internet of things, Networking, Vulnerability analysis, Research, Education, PhD degree, Cyber sciences, Data science, Cybersecurity research, Digital forensics research, Machine learning research, Bioinformatics research, Internet of things research, Networking research, Vulnerability analysis research, Computer science research, Cybersecurity education, Digital forensics education, Machine learning education, Bioinformatics education, Internet of things education, Networking education, Vulnerability analysis education, Computer science education, PhD program, Cybersecurity program, Digital forensics program, Machine learning program, Bioinformatics program, Internet of things program, Networking program, Vulnerability analysis program, Computer science program, Graduate studies, Cybersecurity graduate studies, Digital forensics graduate studies, Machine learning graduate studies, Bioinformatics graduate studies, Internet of things graduate studies, Networking graduate studies, Vulnerability analysis graduate studies, Computer science graduate studies, PhD studies, Cybersecurity studies, Digital forensics studies, Machine learning studies, Bioinformatics studies, Internet of things studies, Networking studies, Vulnerability analysis studies, Computer science studies, Academic research, Cybersecurity research, Digital forensics research, Machine learning research, Bioinformatics research, Internet of things research, Networking research, Vulnerability analysis research, Computer science research, Professional development, Cybersecurity professional development, Digital forensics professional development, Machine learning professional development, Bioinformatics professional development, Internet of things professional development, Networking professional development, Vulnerability analysis professional development, Computer science professional development, Continuing education, Cybersecurity continuing education, Digital forensics continuing education, Machine learning continuing education, Bioinformatics continuing education, Internet of things continuing education, Networking continuing education, Vulnerability analysis continuing education, Computer science continuing education, Career advancement, Cybersecurity career advancement, Digital forensics career advancement, Machine learning career advancement, Bioinformatics career advancement, Internet of things career advancement, Networking career advancement, Vulnerability analysis career advancement, Computer science career advancement, Professional portfolio, Cybersecurity portfolio, Digital forensics portfolio, Machine learning portfolio, Bioinformatics portfolio, Internet of things portfolio, Networking portfolio">
    <meta name="author" content="Seth Barrett">


    <meta property="og:site_name" content="Seth Barrett - Home">
    <meta name="twitter:domain" property="twitter:domain" content="sethbarrett.xyz">
    <meta name="og:title" property="og:title" content="Seth Barrett - Home">
    <meta property="og:description"
        content="In this post, we'll learn about using the requests and Beautiful Soup libraries in Python for web scraping and parsing. We'll look at how to make HTTP requests with requests, and how to extract and navigate data from HTML and XML documents with Beautiful Soup. We'll also see how to use these libraries together to scrape data from a webpage. Requests and Beautiful Soup are popular and well-documented libraries that are useful for a variety of tasks such as data mining, data analytics, and automating tasks.">
    <meta name="twitter:description" property="twitter:description"
        content="In this post, we'll learn about using the requests and Beautiful Soup libraries in Python for web scraping and parsing. We'll look at how to make HTTP requests with requests, and how to extract and navigate data from HTML and XML documents with Beautiful Soup. We'll also see how to use these libraries together to scrape data from a webpage. Requests and Beautiful Soup are popular and well-documented libraries that are useful for a variety of tasks such as data mining, data analytics, and automating tasks.">
    <meta name="og:image" content="https://sethbarrett.xyz/photos/me.webp">


    <meta property="twitter:card" content="https://sethbarrett.xyz/photos/me.webp">
    <meta name="twitter:image:src" property="twitter:image:src" content="https://sethbarrett.xyz/photos/me.webp">
    <meta name="twitter:image" property="twitter:image" content="https://sethbarrett.xyz/photos/me.webp">
    <meta name="og:image:alt" property="og:image:alt" content="Me">

    <meta property="og:url" content="sethbarrett.xyz">
    <meta property="og:type" content="website">
    <title>Daily Blog Post: January 14th, 2023</title>


    <!-- Update CSS Versions when changed -->
    <link rel="stylesheet" href="../selfie.css?v=1.0.9" />
    <link rel="stylesheet" href="../selfie_tablet.css?v=1.0.9" media="only screen and (max-width: 1000px)" />
    <link rel="stylesheet" href="../selfie_mobile.css?v=1.0.9" media="only screen and (max-width: 600px)" />
</head>

<body>
    <div id="wrapper">
        <header>
            <h1>Seth Barrett</h1>
            <h2>Daily Blog Post: January 14th, 2023</h2>
        </header>
        <nav>
            <ul>
                <li><a href="../index.html">Home</a></li>
                <li><a href="../experience.html">Experience</a></li>
                <li><a href="../education.html">Education</a></li>
                <li><a href="../blog.html">Blog</a></li>
                <li><a href="../contact.html">Contact Me</a></li>
            </ul>
        </nav>
        <main>
            <div id="blog">
                
                <div class="blog">
                    <h4>Jan 14th, 2023</h4>
                    <div class='title'>Exploring Web Scraping and Parsing with requests and Beautiful Soup in Python</div>

                    <img src="photos/1_14_23.webp" alt="Python8" width="250" height="445" />

                    <p>
                        Hello and welcome back to my intro to Python series! 
                        In the previous posts, we learned about advanced concepts such as exception handling, object-oriented programming, inheritance, and polymorphism. 
                        These are powerful tools that allow you to write more organized and reusable code, and they are an important part of any Python programmer's toolkit. 
                        In this post, we're going to look at two popular libraries for web scraping and parsing: <code>requests</code> and <code>Beautiful Soup</code>.
                    </p>
                    <p>
                        Web scraping is a technique for extracting data from websites, and it is a useful tool for a wide range of tasks, such as data mining, data analytics, and even automating tasks. 
                        In Python, you can use the requests library to make HTTP requests to websites and retrieve the HTML or other data that they return. 
                        The Beautiful Soup library is a popular library for parsing and navigating HTML and XML data, which makes it easy to extract the data that you need from a website.
                    </p>
                    <p>
                        I am currently using both <code>requests</code> and <code>Beautiful Soup</code> for my Vault research project, where I am web scraping 3rd party Android app stores to keep an updated list of all available apps. 
                        I am also using these libraries for my IoT research project, where I am web scraping IoT device manufacturing sites to keep an updated list of all manufactured IoT devices. 
                        Both of these projects require me to retrieve and parse data from multiple websites, and the combination of <code>requests</code> and <code>Beautiful Soup</code> makes it easy to do so efficiently and effectively. 
                        We'll be learning more about how to use these libraries in Python in this post.
                    </p>
                    <p>
                        <code>requests</code> is a library for making HTTP requests in Python. 
                        It allows you to send HTTP requests (such as GET, POST, PUT, DELETE) to a web server and receive a response. 
                        For example:
                    </p>
<p><pre>import requests

response = requests.get("http://www.example.com")
print(response.status_code)  
# prints 200 if the request is successful

print(response.text)  
# prints the HTML content of the webpage </pre></p>
                    <p>
                        <code>Beautiful Soup</code> is a library for parsing HTML and XML documents. It allows you to extract data from a webpage in a more convenient and efficient way than manually parsing the HTML. For example:
                    </p>
<p><pre>from bs4 import BeautifulSoup

html = """
&lt;html&gt;
    &lt;head&gt;
        &lt;title&gt;My webpage&lt;/title&gt;
    &lt;/head&gt;
    &lt;body&gt;
    &lt;h1&gt;Hello, world!&lt;/h1&gt;
    &lt;p&gt;This is my webpage&lt;/p&gt;
    &lt;/body&gt;
&lt;/html&gt;
"""

soup = BeautifulSoup(html, "html.parser")
title = soup.find("title").string
print(title)  
# prints "My webpage" </pre></p>
                    <p>
                        You can use <code>requests</code> and <code>Beautiful Soup</code> together to scrape data from a webpage. 
                        For example:
                    </p>
<p><pre>import requests
from bs4 import BeautifulSoup

url = "http://www.example.com"
response = requests.get(url)
soup = BeautifulSoup(response.text, "html.parser")

# Extract data from the webpage using Beautiful Soup
title = soup.find("title").string
paragraphs = soup.find_all("p")

# Print the extracted data
print(title)
for p in paragraphs:
    print(p.string) </pre></p>
                    <p>
                        <code>requests</code> and <code>Beautiful Soup</code> are just two of the many libraries available for web scraping and parsing in Python. 
                        They are widely used and well-documented, making them a good choice for beginners.
                    </p>
                    <p>
                        I hope this post has introduced you to the <code>requests</code> and <code>Beautiful Soup</code> libraries in Python. 
                        In the next post, we'll look at some more advanced topics in Python. 
                        Thanks for reading!
                    </p>

                        <!-- Desc: In this post, we'll learn about using the requests and Beautiful Soup libraries in Python for web scraping and parsing. We'll look at how to make HTTP requests with requests, and how to extract and navigate data from HTML and XML documents with Beautiful Soup. We'll also see how to use these libraries together to scrape data from a webpage. Requests and Beautiful Soup are popular and well-documented libraries that are useful for a variety of tasks such as data mining, data analytics, and automating tasks.  -->
                </div>
            </div>
        </main>
        <footer>
            <!-- Copyright &copy; [2023], [Seth Barrett]
            <br /> -->
            <b>
                Email:
            </b>
            <a href="mailto:sebarrett@augusta.edu">sebarrett@augusta.edu</a>
            <br />
            <b>
                Blog RSS Feed:
            </b>
            <a href="sethbarrett.xyz/blogposts/rss.xml">sethbarrett.xyz/blogposts/rss.xml</a>
            <br />
            <b>
                Linkedin Profile:
            </b>
            <a href="https://www.linkedin.com/in/975833b14567812q">LinkedIn</a>
            <br />
            <b>
                GitHub:
            </b>
            <a href="https://github.com/sethbarrett50">GitHub</a>
            <br />
            <b>
                Privacy Policy:
            </b>
            <a href="privacy.html">Privacy Policy</a>
        </footer>
    </div>
</body>
</html>