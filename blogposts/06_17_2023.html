<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />

    <meta name="robots" content="index, follow">

    <meta name="description"
        content="This blog post is a part of a detailed series exploring the various functionalities of the Julia programming language, specifically focusing on web scraping using HTTP.jl and Gumbo.jl packages. The post offers a practical introduction to web scraping in Julia, which involves extracting data from websites by fetching and parsing web content. The step-by-step tutorial demonstrates how to fetch web pages with HTTP.jl, parse HTML content with Gumbo.jl, and extract specific elements using Cascadia.jl in conjunction with Gumbo.jl. By navigating through each process in a structured manner, the guide effectively simplifies web scraping for readers, allowing them to conveniently extract, analyze, and process data from various websites.">
    <meta name="keywords"
        content="Seth, Seth Barrett, Augusta, Augusta University, AU, SCCS, School of Computer and Cyber Science, Barrett, Dorai, PhD, Computer science, Cybersecurity, Digital forensics, Machine learning, Bioinformatics, Internet of things, Networking, Vulnerability analysis, Research, Education, PhD degree, Cyber sciences, Data science, Cybersecurity research, Digital forensics research, Machine learning research, Bioinformatics research, Internet of things research, Networking research, Vulnerability analysis research, Computer science research, Cybersecurity education, Digital forensics education, Machine learning education, Bioinformatics education, Internet of things education, Networking education, Vulnerability analysis education, Computer science education, PhD program, Cybersecurity program, Digital forensics program, Machine learning program, Bioinformatics program, Internet of things program, Networking program, Vulnerability analysis program, Computer science program, Graduate studies, Cybersecurity graduate studies, Digital forensics graduate studies, Machine learning graduate studies, Bioinformatics graduate studies, Internet of things graduate studies, Networking graduate studies, Vulnerability analysis graduate studies, Computer science graduate studies, PhD studies, Cybersecurity studies, Digital forensics studies, Machine learning studies, Bioinformatics studies, Internet of things studies, Networking studies, Vulnerability analysis studies, Computer science studies, Academic research, Cybersecurity research, Digital forensics research, Machine learning research, Bioinformatics research, Internet of things research, Networking research, Vulnerability analysis research, Computer science research, Professional development, Cybersecurity professional development, Digital forensics professional development, Machine learning professional development, Bioinformatics professional development, Internet of things professional development, Networking professional development, Vulnerability analysis professional development, Computer science professional development, Continuing education, Cybersecurity continuing education, Digital forensics continuing education, Machine learning continuing education, Bioinformatics continuing education, Internet of things continuing education, Networking continuing education, Vulnerability analysis continuing education, Computer science continuing education, Career advancement, Cybersecurity career advancement, Digital forensics career advancement, Machine learning career advancement, Bioinformatics career advancement, Internet of things career advancement, Networking career advancement, Vulnerability analysis career advancement, Computer science career advancement, Professional portfolio, Cybersecurity portfolio, Digital forensics portfolio, Machine learning portfolio, Bioinformatics portfolio, Internet of things portfolio, Networking portfolio">
    <meta name="author" content="Seth Barrett">


    <meta property="og:site_name" content="Seth Barrett - Home">
    <meta name="twitter:domain" property="twitter:domain" content="sethbarrett.xyz">
    <meta name="og:title" property="og:title" content="Seth Barrett - Home">
    <meta property="og:description"
        content="This blog post is a part of a detailed series exploring the various functionalities of the Julia programming language, specifically focusing on web scraping using HTTP.jl and Gumbo.jl packages. The post offers a practical introduction to web scraping in Julia, which involves extracting data from websites by fetching and parsing web content. The step-by-step tutorial demonstrates how to fetch web pages with HTTP.jl, parse HTML content with Gumbo.jl, and extract specific elements using Cascadia.jl in conjunction with Gumbo.jl. By navigating through each process in a structured manner, the guide effectively simplifies web scraping for readers, allowing them to conveniently extract, analyze, and process data from various websites.">
    <meta name="twitter:description" property="twitter:description"
        content="This blog post is a part of a detailed series exploring the various functionalities of the Julia programming language, specifically focusing on web scraping using HTTP.jl and Gumbo.jl packages. The post offers a practical introduction to web scraping in Julia, which involves extracting data from websites by fetching and parsing web content. The step-by-step tutorial demonstrates how to fetch web pages with HTTP.jl, parse HTML content with Gumbo.jl, and extract specific elements using Cascadia.jl in conjunction with Gumbo.jl. By navigating through each process in a structured manner, the guide effectively simplifies web scraping for readers, allowing them to conveniently extract, analyze, and process data from various websites.">
    <meta name="og:image" content="https://sethbarrett.xyz/photos/me.webp">


    <meta property="twitter:card" content="https://sethbarrett.xyz/photos/me.webp">
    <meta name="twitter:image:src" property="twitter:image:src" content="https://sethbarrett.xyz/photos/me.webp">
    <meta name="twitter:image" property="twitter:image" content="https://sethbarrett.xyz/photos/me.webp">
    <meta name="og:image:alt" property="og:image:alt" content="Me">

    <meta property="og:url" content="sethbarrett.xyz">
    <meta property="og:type" content="website">
    <title>Daily Blog Post: June 17th, 2023</title>


    <!-- Update CSS Versions when changed -->
    <link rel="stylesheet" href="../selfie.css?v=1.0.8" />
    <link rel="stylesheet" href="../selfie_tablet.css?v=1.0.8" media="only screen and (max-width: 1000px)" />
    <link rel="stylesheet" href="../selfie_mobile.css?v=1.0.8" media="only screen and (max-width: 600px)" />
</head>

<body>
    <div id="wrapper">
        <header>
            <h1>Seth Barrett</h1>
            <h2>Daily Blog Post: June 17th, 2023</h2>
        </header>
        <nav>
            <ul>
                <li><a href="../index.html">Home</a></li>
                <li><a href="../experience.html">Experience</a></li>
                <li><a href="../education.html">Education</a></li> 
                <li><a href="../blog.html">Blog</a></li>
                <li><a href="../contact.html">Contact Me</a></li>
            </ul>
        </nav>
        <main>
            <div id="blog">
                
                <div class="blog">
                    <img src="photos/06_17_23.webp" alt="go" width="250" height="445" />
                    <h4>June 17th, 2023</h4>
                    <div class='title'>Web Scraping in Julia: Exploring HTTP.jl and Gumbo.jl</div>

                    <p>
                        Welcome back to our series on Julia, the high-performance programming language designed for scientific computing. We have covered various aspects of the language, including setting up a coding environment, syntax and unique features, data science, machine learning techniques, optimization strategies, working with databases, and building web applications. In this post, we will delve into web scraping in Julia, exploring how to fetch and parse web content using the HTTP.jl and Gumbo.jl packages.
                    </p>
                    <h5>Overview of Web Scraping Packages in Julia</h5>
                    <p>
                        Web scraping is the process of extracting data from websites by fetching web pages, parsing the HTML content, and extracting the desired information. In Julia, there are several packages available for web scraping, including:
                    </p>
                    <ol>
                        <li><b>HTTP.jl</b>: A package for making HTTP requests, which can be used to fetch web pages.</li>
                        <li><b>Gumbo.jl</b>: A package for parsing HTML content, based on the Google-developed Gumbo library.</li>
                        <li><b>Cascadia.jl</b>: A package for selecting HTML elements using CSS selectors, which can be used in conjunction with Gumbo.jl.</li>
                    </ol>
                    <p>In this post, we will focus on using HTTP.jl for fetching web pages and Gumbo.jl for parsing the HTML content.</p>
                    <h5>Fetching Web Pages with HTTP.jl</h5>
                    <p>
                        To fetch a web page using HTTP.jl, you first need to install the package:
                    </p>
<p><pre>import Pkg
Pkg.add("HTTP")</pre></p>
                    <p>Now, you can use the <code>HTTP.get</code> function to fetch a web page:</p>
<p><pre>using HTTP

url = "https://example.com"
response = HTTP.get(url)

# Check if the request was successful
if response.status == 200
    println("Successfully fetched the web page!")
else
    println("Failed to fetch the web page. Status code: ", response.status)
end</pre></p>
                    <p>
                        The <code>HTTP.get</code> function returns an <code>HTTP.Response</code> object, which contains the HTTP status code, headers, and body (the HTML content of the web page). To access the HTML content, you can use the <code>response.body</code> attribute:
                    </p>
                    <p><pre>html_content = String(response.body)</pre></p>
                    <h5>Parsing HTML Content with Gumbo.jl</h5>
                    <p>To parse the HTML content of a web page, you can use the Gumbo.jl package. First, let's install the package:</p>
<p><pre>import Pkg
Pkg.add("Gumbo")</pre></p>
                    <p>
                        Now, you can use the <code>Gumbo.parsehtml</code> function to parse the HTML content:
                    </p>
<p><pre>using Gumbo

html_document = Gumbo.parsehtml(html_content)</pre></p>
                    <p>
                        The <code>Gumbo.parsehtml</code> function returns an <code>HTMLDocument</code> object, which represents the structure of the HTML content. The <code>HTMLDocument</code> object has a <code>root</code> attribute, which is the root element of the HTML content (usually the &<code>lt;html&gt;</code> element).
                    </p>
                    <p>To traverse the HTML content, you can use the attributes and functions provided by the Gumbo.jl package:</p>
                    <ul>
                        <li><code>element.children</code>: A list of child elements of the given element.</li>
                        <li><code>element.attributes</code>: A dictionary of attributes of the given element.</li>
                        <li><code>Gumbo.bytag(element, tag_name)</code>: A function that returns a list of elements with the given tag name.</li>
                    </ul>
                    <p>
                        For example, to extract all the links from a web page, you can use the following code:
                    </p>
<p><pre># Find all the &lt;a&gt; elements
link_elements = Gumbo.bytag(html_document.root, "a")

# Extract the href attribute of each &lt;a&gt; element
links = [link.attributes["href"] for link in link_elements if haskey(link.attributes, "href")]

# Print the links
for link in links
    println(link)
end</pre></p>
                    <h5>Using Cascadia.jl for Selecting HTML Elements</h5>
                    <p>To select HTML elements using CSS selectors, you can use the Cascadia.jl package in conjunction with Gumbo.jl. First, let's install the package:</p>
<p><pre>import Pkg
Pkg.add("Cascadia")</pre></p>
                    <p>
                        Now, you can use the <code>Cascadia.select</code> function to select elements based on a CSS selector:
                    </p>
<p><pre>using Cascadia

# Define a CSS selector
selector = "div.article &gt; h2"

# Select the elements that match the CSS selector
selected_elements = Cascadia.select(html_document.root, selector)

# Print the text content of the selected elements
for element in selected_elements
    println(Gumbo.text(element))
end</pre></p>
                    <p>
                        The <code>Cascadia.select</code> function returns a list of elements that match the given CSS selector. You can then extract the desired information from the selected elements using the attributes and functions provided by the Gumbo.jl package.
                    </p>
                    <h5>Conclusion</h5>
                    <p>
                        In this post, we introduced web scraping in Julia using the HTTP.jl and Gumbo.jl packages. We demonstrated how to fetch web pages, parse HTML content, and extract information from the parsed content using various techniques. With these tools, you can efficiently extract data from websites, making it easier to analyze and process the information as needed.
                    </p>
                    <p>
                        As we continue our series on Julia, stay tuned for more posts covering a wide range of topics, from data visualization and statistical analysis to advanced numerical computing and scientific applications. Keep learning, and happy coding!
                    </p>
                    

                    
                    
                    
                    

                    
                    <button><a href="./06_18_2023.html">Next Post in Series</a></button>
                    <button><a href="./06_16_2023.html">Previous Post in Series</a></button>

                    
                    <!-- Desc: This blog post is a part of a detailed series exploring the various functionalities of the Julia programming language, specifically focusing on web scraping using HTTP.jl and Gumbo.jl packages. The post offers a practical introduction to web scraping in Julia, which involves extracting data from websites by fetching and parsing web content. The step-by-step tutorial demonstrates how to fetch web pages with HTTP.jl, parse HTML content with Gumbo.jl, and extract specific elements using Cascadia.jl in conjunction with Gumbo.jl. By navigating through each process in a structured manner, the guide effectively simplifies web scraping for readers, allowing them to conveniently extract, analyze, and process data from various websites.  -->
                        
                </div>
            </div>
        </main>
        <footer>
            <!-- Copyright &copy; [2023], [Seth Barrett]
            <br /> -->
            <b>
                Email:
            </b>
            <a href="mailto:sebarrett@augusta.edu">sebarrett@augusta.edu</a>
            <br />
            <b>
                Blog RSS Feed:
            </b>
            <a href="sethbarrett.xyz/blogposts/rss.xml">sethbarrett.xyz/blogposts/rss.xml</a>
            <br />
            <b>
                Linkedin Profile:
            </b>
            <a href="https://www.linkedin.com/in/975833b14567812q">LinkedIn</a>
            <br />
            <b>
                GitHub:
            </b>
            <a href="https://github.com/sethbarrett50">GitHub</a>
            <br />
            <b>
                Privacy Policy:
            </b>
            <a href="privacy.html">Privacy Policy</a>
        </footer>
    </div>
</body>
</html>