<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
    <title>The Daily Grind</title>
    <link>https://www.sethbarrett.xyz/</link>
    <description>Recent content on my blog] </description>
    <language>en-us</language>
    <atom:link href="https://sethbarrett.xyz/rss.xml" rel="self" type="application/rss+xml"/>
    <item>
        <title>>My Experience Setting Up and Using Diffusion Bee: AI Image Creating Software</title>
        <link>https://sethbarrett.xyz/blogposts/1_3_2023.html/</link>
        <pubDate>Tue, 3 Jan 2023 18:18:40 -0500</pubDate>
        <guid>https://sethbarrett.xyz/blogposts/1_3_2023.html/</guid>
        <description> 
            <img src="photos/stableDiff.webp" alt="Stable Diffusion 1" width="250" height="445" />

                    <p>
                        Hey everyone!
                    </p>
                    <p>
                        I wanted to share with you my experience today with setting up and using Diffusion Bee, an AI image creating software. 
                        I used it on my MacBook Pro, which has a M1 Max chip and 64Gb of ram. 
                        I figured that should be enough to run the software smoothly and create high quality AI art.

                    </p>
                    <p>
                        I used the DiffusionBee UI for this, and I have to say it was a fairly easy process. 
                        You can find the github page <a href="https://github.com/divamgupta/diffusionbee-stable-diffusion-ui">here</a> and the main website <a href="https://diffusionbee.com/">here</a>.
                    </p>
                    <p>
                        The setup process was straightforward, though it did take a bit of time. 
                        First, I had to download the dmg file from the main website and add it to my applications folder. 
                        There are two versions of DiffusionBee available for Apple Silicon chips, and I opted for the high quality version since my MacBook Pro has good specs. 
                        The initial dmg file was only 500Mb, but once you start up the application, 8 models need to be downloaded, so make sure you have at least 8Gb of free space and some time to allow the models to download.

                    </p>
                    <p>
                        DiffusionBee has several different modes of use, including text to image, image to image, in-painting and out-painting. Here's a breakdown of each mode:
                    </p>
                    <ul>
                        <li>
                            Text to image generates an image based on an input string
                        </li>
                        <div class="exPic"><figure>
                            <img src="photos/sdI2I.webp" alt="Text to Image" width="250" height="445" />
                            <figcaption>Image created from the text prompt "create an image representing IoT security, Cel Shading"
                            </figcaption>
                        </figure></div>
                        <li>
                            Image to image modifies an image provided based on an input string
                        </li>
                        <div class="exPic"><figure>
                            <img src="photos/alexa1.webp" alt="Image to Image1" width="250" height="445" />
                            <img src="photos/alexa2.webp" alt="Image to Image2" width="250" height="445" />
                            <figcaption>Image on right created from left image and text prompt "draw in cell shade style"
                            </figcaption>
                        </figure></div>
                        <li>
                            In-painting removes or adds objects to a region of a provided image based on an input string
                        </li>
                        <div class="exPic"><figure>
                            <img src="photos/ip1.webp" alt="In-Painting1" width="250" height="445" />
                            <img src="photos/ip2.webp" alt="In-Painting2" width="250" height="445" />
                            <figcaption>Image on right created from left image and text prompt "add a smartphone" with the white area colored in
                            </figcaption>
                        </figure></div>
                        <li>
                            Out-painting expands an image outward using an input string
                        </li>
                        <div class="exPic"><figure>
                            <img src="photos/op1.webp" alt="Out-Painting1" width="250" height="445" />
                            <img src="photos/op2.webp" alt="Out-Painting2" width="250" height="445" />
                            <figcaption>Image on right created from left image and text prompt "draw more mountains"
                            </figcaption>
                        </figure></div>
                        <!-- <li>
                            Upscaling increases the resolution of a provided image
                        </li> -->
                    </ul>
                    <p>
                        One of the main reasons I really like DiffusionBee is that it runs entirely locally on my machine without communicating with any cloud services. Plus, its search system allows advanced control over the machine learning program. If you're looking for a way to run stable diffusion and you have a MacBook Pro that meets the minimum specs, I highly recommend checking out DiffusionBee!
                    </p>
        </description>
    </item>
</channel>
</rss>

